{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbae8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc520c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train,y_train = X_train_full[:-5000],y_train_full[:-5000]\n",
    "X_valid,y_valid = X_train_full[-5000:],y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.max(X_train),np.min(X_train)\n",
    "X_train = X_train.astype(np.float32) / 255.0\n",
    "X_valid = X_valid.astype(np.float32) / 255.0\n",
    "X_test = X_test.astype(np.float32) / 255.0\n",
    "np.max(X_train),np.min(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1de245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0],cmap=\"binary\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf92068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense,InputLayer\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=[28,28]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation=\"relu\"))\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "model.add(Dense(75,activation=\"relu\"))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36bac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68c9ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train).unsqueeze(1) / 255.0\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define a simple model\n",
    "class FashionMNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = FashionMNISTModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "train_N = len(train_dataset)\n",
    "\n",
    "def get_batch_accuracy(output, y, N):\n",
    "    pred = output.argmax(dim=1)\n",
    "    correct = pred.eq(y).sum().item()\n",
    "    return correct / N\n",
    "\n",
    "def train():\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = loss_function(output, y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        accuracy += get_batch_accuracy(output, y, train_N)\n",
    "    print('Train - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
